"""
Module de recommandation intelligente utilisant RAG avec LangChain
"""
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema import HumanMessage, SystemMessage
import os
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

class RecommenderSystem:
    def __init__(self, groq_api_key=None):
        """
        Initialise le syst√®me de recommandation avec LangChain et Groq
        """
        # Utiliser la cl√© API fournie ou celle de l'environnement
        self.api_key = groq_api_key or os.getenv("GROQ_API_KEY")
        
        if not self.api_key:
            raise ValueError("‚ùå Cl√© API Groq manquante. Veuillez fournir GROQ_API_KEY dans .env")
        
        # Initialiser le mod√®le LLaMA 3 via Groq
        print("üß† Initialisation du mod√®le LLaMA 3 via Groq...")
        self.llm = ChatGroq(
            temperature=0.7,
            groq_api_key=self.api_key,
            model_name="llama3-70b-8192"  # Mod√®le gratuit et performant
        )
        
        # Template du prompt pour la recommandation
        self.recommendation_prompt = PromptTemplate(
            input_variables=["query", "context", "student_level"],
            template="""
            Tu es un assistant acad√©mique sp√©cialis√© dans la recommandation de sujets de m√©moire.
            
            CONTEXTE (anciens sujets de m√©moire):
            {context}
            
            REQU√äTE DE L'√âTUDIANT:
            {query}
            
            NIVEAU DE L'√âTUDIANT:
            {student_level}
            
            T√ÇCHE:
            Analyse la requ√™te de l'√©tudiant et recommande EXACTEMENT 3 sujets de m√©moire pertinents.
            
            R√àGLES STRICTES:
            1. Propose EXACTEMENT 3 sujets diff√©rents
            2. Adapte les recommandations au niveau sp√©cifi√© ({student_level})
            3. Pour chaque sujet, fournis:
               - Titre propos√© (bas√© sur les sujets existants mais adapt√©)
               - D√©partement concern√©
               - Br√®ve justification (1-2 phrases)
               - Adaptation au niveau de l'√©tudiant
            4. R√©ponds UNIQUEMENT en fran√ßais
            5. Sois cr√©atif mais r√©aliste
            
            FORMAT DE R√âPONSE:
            üìò **RECOMMANDATIONS PERSONNALIS√âES**
            
            üéØ **Sujet 1: [Titre]**
            üìç D√©partement: [D√©partement]
            ‚úÖ Pourquoi ce sujet: [Justification]
            üéì Adaptation niveau: [Adaptation au niveau]
            
            üîÅ R√©p√®te ce format pour les 3 sujets
            
            COMMENCE TA R√âPONSE DIRECTEMENT AVEC "üìò **RECOMMANDATIONS PERSONNALIS√âES**"
            """
        )
        
        # Initialiser la cha√Æne LangChain
        self.chain = LLMChain(
            llm=self.llm,
            prompt=self.recommendation_prompt,
            verbose=False
        )
    
    def generate_recommendations(self, query, context, student_level="interm√©diaire"):
        """
        G√©n√®re des recommandations personnalis√©es
        """
        try:
            print(f"ü§î G√©n√©ration de recommandations pour: '{query}'")
            
            # Pr√©parer le contexte format√©
            context_str = "\n\n".join([
                f"Titre: {doc['titre']}\n"
                f"R√©sum√©: {doc['resume']}\n"
                f"D√©partement: {doc['departement']}\n"
                f"Niveau: {doc['niveau']}"
                for doc in context
            ])
            
            # Ex√©cuter la cha√Æne
            response = self.chain.run(
                query=query,
                context=context_str,
                student_level=student_level
            )
            
            return response
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration: {e}")
            return f"Erreur: {str(e)}"
    
    def analyze_student_query(self, query):
        """
        Analyse la requ√™te de l'√©tudiant pour extraire des informations cl√©s
        """
        analysis_prompt = f"""
        Analyse la requ√™te suivante d'un √©tudiant cherchant un sujet de m√©moire.
        Identifie:
        1. Le domaine/th√®me principal
        2. Le niveau implicite (d√©butant/interm√©diaire/avanc√©)
        3. Les mots-cl√©s techniques
        4. Le d√©partement concern√© (si mentionn√©)
        
        Requ√™te: "{query}"
        
        R√©ponds en fran√ßais avec un format clair.
        """
        
        try:
            messages = [
                SystemMessage(content="Tu es un expert en analyse de requ√™tes acad√©miques."),
                HumanMessage(content=analysis_prompt)
            ]
            
            response = self.llm(messages)
            return response.content
        except:
            return "Analyse non disponible"